{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4161775,"sourceType":"datasetVersion","datasetId":2456516}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"tr1gg3rtrash/yoga-posture-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:47:28.892937Z","iopub.execute_input":"2024-12-07T15:47:28.893538Z","iopub.status.idle":"2024-12-07T15:47:29.786058Z","shell.execute_reply.started":"2024-12-07T15:47:28.893494Z","shell.execute_reply":"2024-12-07T15:47:29.785220Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/yoga-posture-dataset\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom matplotlib import pyplot as plt\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:44:14.797838Z","iopub.execute_input":"2024-12-06T15:44:14.798557Z","iopub.status.idle":"2024-12-06T15:44:14.803894Z","shell.execute_reply.started":"2024-12-06T15:44:14.798504Z","shell.execute_reply":"2024-12-06T15:44:14.802578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set dataset path\ndataset_path = \"/kaggle/input/yoga-posture-dataset\"\n\n# List pose folders\nposes = os.listdir(dataset_path)\nprint(f\"Total poses: {len(poses)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:44:29.593807Z","iopub.execute_input":"2024-12-06T15:44:29.594213Z","iopub.status.idle":"2024-12-06T15:44:29.610258Z","shell.execute_reply.started":"2024-12-06T15:44:29.594176Z","shell.execute_reply":"2024-12-06T15:44:29.609081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter out non-directory items\nposes = [pose for pose in poses if os.path.isdir(os.path.join(dataset_path, pose))]\nprint(f\"Total valid pose folders: {len(poses)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:55:20.469289Z","iopub.execute_input":"2024-12-06T15:55:20.469710Z","iopub.status.idle":"2024-12-06T15:55:20.532370Z","shell.execute_reply.started":"2024-12-06T15:55:20.469674Z","shell.execute_reply":"2024-12-06T15:55:20.531212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize sample images\nfor pose in poses[:5]:\n    pose_path = os.path.join(dataset_path, pose)\n    sample_image = os.listdir(pose_path)[0]\n    image_path = os.path.join(pose_path, sample_image)\n\n    img = Image.open(image_path)\n    plt.imshow(img)\n    plt.title(pose)\n    plt.axis(\"off\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:55:24.646804Z","iopub.execute_input":"2024-12-06T15:55:24.647297Z","iopub.status.idle":"2024-12-06T15:55:26.064557Z","shell.execute_reply.started":"2024-12-06T15:55:24.647260Z","shell.execute_reply":"2024-12-06T15:55:26.063215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:55:27.553043Z","iopub.execute_input":"2024-12-06T15:55:27.553452Z","iopub.status.idle":"2024-12-06T15:55:27.558828Z","shell.execute_reply.started":"2024-12-06T15:55:27.553418Z","shell.execute_reply":"2024-12-06T15:55:27.557319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths for train and test datasets\ntrain_dir = \"/kaggle/working/train\"\ntest_dir = \"/kaggle/working/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:57:08.634641Z","iopub.execute_input":"2024-12-06T15:57:08.635081Z","iopub.status.idle":"2024-12-06T15:57:08.640484Z","shell.execute_reply.started":"2024-12-06T15:57:08.635047Z","shell.execute_reply":"2024-12-06T15:57:08.639233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:57:13.251578Z","iopub.execute_input":"2024-12-06T15:57:13.252005Z","iopub.status.idle":"2024-12-06T15:57:13.258158Z","shell.execute_reply.started":"2024-12-06T15:57:13.251970Z","shell.execute_reply":"2024-12-06T15:57:13.256866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Source Path:\", os.path.join(pose_path, img))\nprint(\"Destination Path:\", os.path.join(train_dir, pose, img))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:57:50.194815Z","iopub.execute_input":"2024-12-06T15:57:50.195250Z","iopub.status.idle":"2024-12-06T15:57:50.201235Z","shell.execute_reply.started":"2024-12-06T15:57:50.195214Z","shell.execute_reply":"2024-12-06T15:57:50.199962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Process each pose folder\nfor pose in poses:\n    pose_path = os.path.join(dataset_path, pose)\n    images = os.listdir(pose_path)\n    \n    # Split images into train and test sets\n    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n    \n    # Ensure subdirectories exist for each pose\n    os.makedirs(os.path.join(train_dir, pose), exist_ok=True)\n    os.makedirs(os.path.join(test_dir, pose), exist_ok=True)\n    \n    # Copy files to train and test folders\n    for img in train_images:\n        shutil.copy(os.path.join(pose_path, img), os.path.join(train_dir, pose, img))\n    for img in test_images:\n        shutil.copy(os.path.join(pose_path, img), os.path.join(test_dir, pose, img))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:57:58.566428Z","iopub.execute_input":"2024-12-06T15:57:58.566846Z","iopub.status.idle":"2024-12-06T15:58:03.514684Z","shell.execute_reply.started":"2024-12-06T15:57:58.566809Z","shell.execute_reply":"2024-12-06T15:58:03.510464Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Source Path:\", os.path.join(pose_path, img))\nprint(\"Destination Path:\", os.path.join(train_dir, pose, img))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T15:58:03.517771Z","iopub.execute_input":"2024-12-06T15:58:03.518562Z","iopub.status.idle":"2024-12-06T15:58:03.528767Z","shell.execute_reply.started":"2024-12-06T15:58:03.518506Z","shell.execute_reply":"2024-12-06T15:58:03.527094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:08:35.343360Z","iopub.execute_input":"2024-12-06T16:08:35.344326Z","iopub.status.idle":"2024-12-06T16:08:35.349138Z","shell.execute_reply.started":"2024-12-06T16:08:35.344286Z","shell.execute_reply":"2024-12-06T16:08:35.348028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Image dimensions\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:15:08.312496Z","iopub.execute_input":"2024-12-06T16:15:08.313349Z","iopub.status.idle":"2024-12-06T16:15:08.318210Z","shell.execute_reply.started":"2024-12-06T16:15:08.313311Z","shell.execute_reply":"2024-12-06T16:15:08.317085Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load EfficientNetB0 pre-trained on ImageNet\nbase_model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\nbase_model.trainable = False  # Freeze the base model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:09:05.789735Z","iopub.execute_input":"2024-12-06T16:09:05.790141Z","iopub.status.idle":"2024-12-06T16:09:07.695693Z","shell.execute_reply.started":"2024-12-06T16:09:05.790080Z","shell.execute_reply":"2024-12-06T16:09:07.694602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add custom layers for yoga pose classification\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Reduce spatial dimensions\nx = Dense(128, activation='relu')(x)  # Fully connected layer\noutput = Dense(len(poses), activation='softmax')(x)  # Final layer with softmax for classification\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:09:24.107011Z","iopub.execute_input":"2024-12-06T16:09:24.107421Z","iopub.status.idle":"2024-12-06T16:09:24.139319Z","shell.execute_reply.started":"2024-12-06T16:09:24.107386Z","shell.execute_reply":"2024-12-06T16:09:24.138296Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the model\nmodel = Model(inputs=base_model.input, outputs=output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:09:30.254223Z","iopub.execute_input":"2024-12-06T16:09:30.254598Z","iopub.status.idle":"2024-12-06T16:09:30.519445Z","shell.execute_reply.started":"2024-12-06T16:09:30.254566Z","shell.execute_reply":"2024-12-06T16:09:30.518300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:14:54.048120Z","iopub.execute_input":"2024-12-06T16:14:54.049191Z","iopub.status.idle":"2024-12-06T16:14:54.064901Z","shell.execute_reply.started":"2024-12-06T16:14:54.049142Z","shell.execute_reply":"2024-12-06T16:14:54.063880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 / 255,\n    rotation_range=20,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:15:22.488087Z","iopub.execute_input":"2024-12-06T16:15:22.488480Z","iopub.status.idle":"2024-12-06T16:15:22.493984Z","shell.execute_reply.started":"2024-12-06T16:15:22.488448Z","shell.execute_reply":"2024-12-06T16:15:22.492956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simple rescaling for validation\ntest_datagen = ImageDataGenerator(rescale=1.0 / 255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:15:27.215527Z","iopub.execute_input":"2024-12-06T16:15:27.215911Z","iopub.status.idle":"2024-12-06T16:15:27.220693Z","shell.execute_reply.started":"2024-12-06T16:15:27.215876Z","shell.execute_reply":"2024-12-06T16:15:27.219495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:29:31.158620Z","iopub.execute_input":"2024-12-06T16:29:31.159021Z","iopub.status.idle":"2024-12-06T16:29:31.234171Z","shell.execute_reply.started":"2024-12-06T16:29:31.158986Z","shell.execute_reply":"2024-12-06T16:29:31.232999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:29:36.648046Z","iopub.execute_input":"2024-12-06T16:29:36.648453Z","iopub.status.idle":"2024-12-06T16:29:36.682464Z","shell.execute_reply.started":"2024-12-06T16:29:36.648420Z","shell.execute_reply":"2024-12-06T16:29:36.681551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for x, y in train_generator:\n    print(f\"Batch shape: {x.shape}, {y.shape}\")\n    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:29:43.223779Z","iopub.execute_input":"2024-12-06T16:29:43.224365Z","iopub.status.idle":"2024-12-06T16:29:43.813924Z","shell.execute_reply.started":"2024-12-06T16:29:43.224315Z","shell.execute_reply":"2024-12-06T16:29:43.812804Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint, early_stopping]\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:28:59.687952Z","iopub.execute_input":"2024-12-06T16:28:59.688387Z","iopub.status.idle":"2024-12-06T16:28:59.725856Z","shell.execute_reply.started":"2024-12-06T16:28:59.688351Z","shell.execute_reply":"2024-12-06T16:28:59.724319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Training samples: {train_generator.samples}\")\nprint(f\"Validation samples: {test_generator.samples}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:28:17.308867Z","iopub.execute_input":"2024-12-06T16:28:17.309318Z","iopub.status.idle":"2024-12-06T16:28:17.315250Z","shell.execute_reply.started":"2024-12-06T16:28:17.309280Z","shell.execute_reply":"2024-12-06T16:28:17.314011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Steps per epoch: {steps_per_epoch}\")\nprint(f\"Validation steps: {validation_steps}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:30:06.249041Z","iopub.execute_input":"2024-12-06T16:30:06.249913Z","iopub.status.idle":"2024-12-06T16:30:06.283056Z","shell.execute_reply.started":"2024-12-06T16:30:06.249869Z","shell.execute_reply":"2024-12-06T16:30:06.281504Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine-Tune the Model","metadata":{}},{"cell_type":"code","source":"# Unfreeze the base model for fine-tuning\nbase_model.trainable = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:18:20.894883Z","iopub.status.idle":"2024-12-06T16:18:20.895316Z","shell.execute_reply.started":"2024-12-06T16:18:20.895130Z","shell.execute_reply":"2024-12-06T16:18:20.895150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Recompile the model with a lower learning rate\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:18:20.896855Z","iopub.status.idle":"2024-12-06T16:18:20.897423Z","shell.execute_reply.started":"2024-12-06T16:18:20.897146Z","shell.execute_reply":"2024-12-06T16:18:20.897175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fine-tune the model\nfine_tune_history = model.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=5,\n    steps_per_epoch=len(train_generator),\n    validation_steps=len(test_generator)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:18:20.899589Z","iopub.status.idle":"2024-12-06T16:18:20.900144Z","shell.execute_reply.started":"2024-12-06T16:18:20.899842Z","shell.execute_reply":"2024-12-06T16:18:20.899870Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"efficientnet_yoga_pose_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:18:20.901453Z","iopub.status.idle":"2024-12-06T16:18:20.901827Z","shell.execute_reply.started":"2024-12-06T16:18:20.901644Z","shell.execute_reply":"2024-12-06T16:18:20.901662Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# retrial\n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nfrom PIL import Image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:11.496361Z","iopub.execute_input":"2024-12-06T16:40:11.496756Z","iopub.status.idle":"2024-12-06T16:40:12.082714Z","shell.execute_reply.started":"2024-12-06T16:40:11.496724Z","shell.execute_reply":"2024-12-06T16:40:12.081409Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Paths for dataset\ndataset_path = \"/kaggle/input/yoga-posture-dataset\"\ntrain_dir = \"train_data\"\ntest_dir = \"test_data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:15.228921Z","iopub.execute_input":"2024-12-06T16:40:15.230167Z","iopub.status.idle":"2024-12-06T16:40:15.234636Z","shell.execute_reply.started":"2024-12-06T16:40:15.230094Z","shell.execute_reply":"2024-12-06T16:40:15.233547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Parameters\nIMG_SIZE = (224, 224)  # EfficientNet input size\nBATCH_SIZE = 32\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:18.806623Z","iopub.execute_input":"2024-12-06T16:40:18.807026Z","iopub.status.idle":"2024-12-06T16:40:18.811713Z","shell.execute_reply.started":"2024-12-06T16:40:18.806980Z","shell.execute_reply":"2024-12-06T16:40:18.810711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Data Preparation","metadata":{}},{"cell_type":"code","source":"# Create directories for train and test splits\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:31.713708Z","iopub.execute_input":"2024-12-06T16:40:31.714083Z","iopub.status.idle":"2024-12-06T16:40:31.719441Z","shell.execute_reply.started":"2024-12-06T16:40:31.714051Z","shell.execute_reply":"2024-12-06T16:40:31.718410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to handle transparency in images\ndef convert_to_rgb(image_path):\n    with Image.open(image_path) as img:\n        if img.mode in (\"RGBA\", \"P\"):\n            img = img.convert(\"RGB\")\n        return img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:37.526866Z","iopub.execute_input":"2024-12-06T16:40:37.527274Z","iopub.status.idle":"2024-12-06T16:40:37.534008Z","shell.execute_reply.started":"2024-12-06T16:40:37.527242Z","shell.execute_reply":"2024-12-06T16:40:37.532573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split images into train and test folders\nfrom sklearn.model_selection import train_test_split\nimport shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:42.070957Z","iopub.execute_input":"2024-12-06T16:40:42.071379Z","iopub.status.idle":"2024-12-06T16:40:42.076214Z","shell.execute_reply.started":"2024-12-06T16:40:42.071344Z","shell.execute_reply":"2024-12-06T16:40:42.075022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"poses = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\nfor pose in poses:\n    pose_path = os.path.join(dataset_path, pose)\n    images = os.listdir(pose_path)\n    train_images, test_images = train_test_split(images, test_size=0.2, random_state=42)\n\n    os.makedirs(os.path.join(train_dir, pose), exist_ok=True)\n    os.makedirs(os.path.join(test_dir, pose), exist_ok=True)\n\n    for img in train_images:\n        img_path = os.path.join(pose_path, img)\n        shutil.copy(img_path, os.path.join(train_dir, pose, img))\n    for img in test_images:\n        img_path = os.path.join(pose_path, img)\n        shutil.copy(img_path, os.path.join(test_dir, pose, img))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:40:48.194972Z","iopub.execute_input":"2024-12-06T16:40:48.195923Z","iopub.status.idle":"2024-12-06T16:40:54.420229Z","shell.execute_reply.started":"2024-12-06T16:40:48.195882Z","shell.execute_reply":"2024-12-06T16:40:54.419161Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Data Augmentation and Generators","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1.0/255, rotation_range=20, zoom_range=0.2, horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1.0/255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:41:14.839001Z","iopub.execute_input":"2024-12-06T16:41:14.840314Z","iopub.status.idle":"2024-12-06T16:41:14.848157Z","shell.execute_reply.started":"2024-12-06T16:41:14.840257Z","shell.execute_reply":"2024-12-06T16:41:14.845485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\", shuffle=True\n)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\", shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:41:18.934910Z","iopub.execute_input":"2024-12-06T16:41:18.935789Z","iopub.status.idle":"2024-12-06T16:41:19.149511Z","shell.execute_reply.started":"2024-12-06T16:41:18.935748Z","shell.execute_reply":"2024-12-06T16:41:19.148434Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add custom layers\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation=\"relu\"),\n    layers.Dropout(0.3),\n    layers.Dense(len(poses), activation=\"softmax\")\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:41:43.294398Z","iopub.execute_input":"2024-12-06T16:41:43.295390Z","iopub.status.idle":"2024-12-06T16:41:43.309186Z","shell.execute_reply.started":"2024-12-06T16:41:43.295344Z","shell.execute_reply":"2024-12-06T16:41:43.307944Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Model Creation","metadata":{}},{"cell_type":"code","source":"base_model = EfficientNetB0(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\nbase_model.trainable = False  # Freeze base model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:41:38.823639Z","iopub.execute_input":"2024-12-06T16:41:38.824762Z","iopub.status.idle":"2024-12-06T16:41:39.967585Z","shell.execute_reply.started":"2024-12-06T16:41:38.824718Z","shell.execute_reply":"2024-12-06T16:41:39.966413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:41:47.334796Z","iopub.execute_input":"2024-12-06T16:41:47.335865Z","iopub.status.idle":"2024-12-06T16:41:47.347313Z","shell.execute_reply.started":"2024-12-06T16:41:47.335822Z","shell.execute_reply":"2024-12-06T16:41:47.346193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Callbacks","metadata":{}},{"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"best_model.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\n\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:55:53.399427Z","iopub.execute_input":"2024-12-06T16:55:53.400209Z","iopub.status.idle":"2024-12-06T16:55:53.406776Z","shell.execute_reply.started":"2024-12-06T16:55:53.400166Z","shell.execute_reply":"2024-12-06T16:55:53.405543Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Training the Model","metadata":{}},{"cell_type":"code","source":"steps_per_epoch = train_generator.samples // BATCH_SIZE\nvalidation_steps = test_generator.samples // BATCH_SIZE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:56:10.546681Z","iopub.execute_input":"2024-12-06T16:56:10.547071Z","iopub.status.idle":"2024-12-06T16:56:10.552168Z","shell.execute_reply.started":"2024-12-06T16:56:10.547037Z","shell.execute_reply":"2024-12-06T16:56:10.551175Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint, early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T16:56:16.802259Z","iopub.execute_input":"2024-12-06T16:56:16.803490Z","iopub.status.idle":"2024-12-06T17:06:47.810734Z","shell.execute_reply.started":"2024-12-06T16:56:16.803445Z","shell.execute_reply":"2024-12-06T17:06:47.809691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Visualize Training Results","metadata":{}},{"cell_type":"code","source":"def plot_training_history(history):\n    plt.figure(figsize=(12, 5))\n\n    # Accuracy plot\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n    plt.title(\"Accuracy Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Accuracy\")\n    plt.legend()\n\n    # Loss plot\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n    plt.title(\"Loss Over Epochs\")\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T17:06:47.812718Z","iopub.execute_input":"2024-12-06T17:06:47.813080Z","iopub.status.idle":"2024-12-06T17:06:47.821570Z","shell.execute_reply.started":"2024-12-06T17:06:47.813046Z","shell.execute_reply":"2024-12-06T17:06:47.820211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_training_history(history)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T17:06:47.822846Z","iopub.execute_input":"2024-12-06T17:06:47.823332Z","iopub.status.idle":"2024-12-06T17:06:48.306767Z","shell.execute_reply.started":"2024-12-06T17:06:47.823283Z","shell.execute_reply":"2024-12-06T17:06:48.305535Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Evaluation","metadata":{}},{"cell_type":"code","source":"# Generate predictions\ny_true = test_generator.classes\ny_pred = np.argmax(model.predict(test_generator), axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T17:06:48.309419Z","iopub.execute_input":"2024-12-06T17:06:48.309885Z","iopub.status.idle":"2024-12-06T17:07:16.323159Z","shell.execute_reply.started":"2024-12-06T17:06:48.309838Z","shell.execute_reply":"2024-12-06T17:07:16.321947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion Matrix\nconf_matrix = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(12, 10))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=poses, yticklabels=poses)\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"True\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T17:07:16.324574Z","iopub.execute_input":"2024-12-06T17:07:16.324924Z","iopub.status.idle":"2024-12-06T17:07:20.326525Z","shell.execute_reply.started":"2024-12-06T17:07:16.324890Z","shell.execute_reply":"2024-12-06T17:07:20.325344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Classification Report\nprint(classification_report(y_true, y_pred, target_names=poses))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T17:07:20.327989Z","iopub.execute_input":"2024-12-06T17:07:20.328457Z","iopub.status.idle":"2024-12-06T17:07:20.349707Z","shell.execute_reply.started":"2024-12-06T17:07:20.328400Z","shell.execute_reply":"2024-12-06T17:07:20.348620Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# third trial\n","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nimport cv2\nfrom PIL import Image, ImageChops, ImageEnhance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:22.917643Z","iopub.execute_input":"2024-12-07T08:18:22.918014Z","iopub.status.idle":"2024-12-07T08:18:38.567504Z","shell.execute_reply.started":"2024-12-07T08:18:22.917981Z","shell.execute_reply":"2024-12-07T08:18:38.566365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Helper functions (for visualization and ELA)\ndef compute_ela_cv(path, quality):\n    temp_filename = 'temp_file_name.jpeg'\n    SCALE = 15\n    orig_img = cv2.imread(path)\n    orig_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB)\n    \n    cv2.imwrite(temp_filename, orig_img, [cv2.IMWRITE_JPEG_QUALITY, quality])\n\n    compressed_img = cv2.imread(temp_filename)\n    diff = SCALE * cv2.absdiff(orig_img, compressed_img)\n    return diff","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:38.569270Z","iopub.execute_input":"2024-12-07T08:18:38.569840Z","iopub.status.idle":"2024-12-07T08:18:38.576149Z","shell.execute_reply.started":"2024-12-07T08:18:38.569804Z","shell.execute_reply":"2024-12-07T08:18:38.574928Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_to_ela_image(path, quality):\n    temp_filename = 'temp_file_name.jpeg'\n    ela_filename = 'temp_ela.png'\n    image = Image.open(path).convert('RGB')\n    image.save(temp_filename, 'JPEG', quality=quality)\n    temp_image = Image.open(temp_filename)\n\n    ela_image = ImageChops.difference(image, temp_image)\n\n    extrema = ela_image.getextrema()\n    max_diff = max([ex[1] for ex in extrema])\n    if max_diff == 0:\n        max_diff = 1\n\n    scale = 255.0 / max_diff\n    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n    return ela_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:48.688689Z","iopub.execute_input":"2024-12-07T08:18:48.689098Z","iopub.status.idle":"2024-12-07T08:18:48.696730Z","shell.execute_reply.started":"2024-12-07T08:18:48.689062Z","shell.execute_reply":"2024-12-07T08:18:48.695470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_sample(path, extension=None):\n    if extension:\n        items = Path(path).glob(f'*.{extension}')\n    else:\n        items = Path(path).glob(f'*')\n        \n    items = list(items)\n    p = np.random.choice(items)\n    return p.as_posix()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:18:55.100146Z","iopub.execute_input":"2024-12-07T08:18:55.100581Z","iopub.status.idle":"2024-12-07T08:18:55.106584Z","shell.execute_reply.started":"2024-12-07T08:18:55.100541Z","shell.execute_reply":"2024-12-07T08:18:55.105342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set batch size and image size\nBATCH_SIZE = 32\nIMAGE_SIZE = (224, 224)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:01.247437Z","iopub.execute_input":"2024-12-07T08:19:01.247897Z","iopub.status.idle":"2024-12-07T08:19:01.253730Z","shell.execute_reply.started":"2024-12-07T08:19:01.247844Z","shell.execute_reply":"2024-12-07T08:19:01.252086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load dataset\ndataset = \"../input/yoga-posture-dataset\"\nimage_dir = Path(dataset)\nfilepaths = list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.png'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:07.212781Z","iopub.execute_input":"2024-12-07T08:19:07.213932Z","iopub.status.idle":"2024-12-07T08:19:16.394479Z","shell.execute_reply.started":"2024-12-07T08:19:07.213872Z","shell.execute_reply":"2024-12-07T08:19:16.393319Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create DataFrame\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\nimage_df = pd.concat([filepaths, labels], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:16.395996Z","iopub.execute_input":"2024-12-07T08:19:16.396404Z","iopub.status.idle":"2024-12-07T08:19:16.410467Z","shell.execute_reply.started":"2024-12-07T08:19:16.396355Z","shell.execute_reply":"2024-12-07T08:19:16.409270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display a random sample of images\nrandom_index = np.random.randint(0, len(image_df), 16)\nfig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10), subplot_kw={'xticks': [], 'yticks': []})\nfor i, ax in enumerate(axes.flat):\n    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))\n    ax.set_title(image_df.Label[random_index[i]])\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:21.094578Z","iopub.execute_input":"2024-12-07T08:19:21.094973Z","iopub.status.idle":"2024-12-07T08:19:23.126519Z","shell.execute_reply.started":"2024-12-07T08:19:21.094938Z","shell.execute_reply":"2024-12-07T08:19:23.124981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Split into train and test sets\ntrain_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:27.897928Z","iopub.execute_input":"2024-12-07T08:19:27.898340Z","iopub.status.idle":"2024-12-07T08:19:27.909446Z","shell.execute_reply.started":"2024-12-07T08:19:27.898285Z","shell.execute_reply":"2024-12-07T08:19:27.908201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data generators\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    validation_split=0.2\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:35.588568Z","iopub.execute_input":"2024-12-07T08:19:35.588976Z","iopub.status.idle":"2024-12-07T08:19:35.594463Z","shell.execute_reply.started":"2024-12-07T08:19:35.588943Z","shell.execute_reply":"2024-12-07T08:19:35.593224Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:40.092215Z","iopub.execute_input":"2024-12-07T08:19:40.092607Z","iopub.status.idle":"2024-12-07T08:19:40.098210Z","shell.execute_reply.started":"2024-12-07T08:19:40.092574Z","shell.execute_reply":"2024-12-07T08:19:40.096947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:19:51.488908Z","iopub.execute_input":"2024-12-07T08:19:51.489332Z","iopub.status.idle":"2024-12-07T08:19:52.596483Z","shell.execute_reply.started":"2024-12-07T08:19:51.489293Z","shell.execute_reply":"2024-12-07T08:19:52.595458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:27:44.928968Z","iopub.execute_input":"2024-12-07T08:27:44.929381Z","iopub.status.idle":"2024-12-07T08:27:46.102486Z","shell.execute_reply.started":"2024-12-07T08:27:44.929344Z","shell.execute_reply":"2024-12-07T08:27:46.100952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:27:50.153755Z","iopub.execute_input":"2024-12-07T08:27:50.154216Z","iopub.status.idle":"2024-12-07T08:27:50.408612Z","shell.execute_reply.started":"2024-12-07T08:27:50.154084Z","shell.execute_reply":"2024-12-07T08:27:50.407333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load EfficientNetB0 model\nbase_model = EfficientNetB0(\n    input_shape=(224, 224, 3),\n    include_top=False,\n    weights='imagenet',\n    pooling='avg'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:27:54.727358Z","iopub.execute_input":"2024-12-07T08:27:54.728784Z","iopub.status.idle":"2024-12-07T08:27:58.580706Z","shell.execute_reply.started":"2024-12-07T08:27:54.728725Z","shell.execute_reply":"2024-12-07T08:27:58.579472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model.trainable = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:27:59.801253Z","iopub.execute_input":"2024-12-07T08:27:59.801687Z","iopub.status.idle":"2024-12-07T08:27:59.810802Z","shell.execute_reply.started":"2024-12-07T08:27:59.801650Z","shell.execute_reply":"2024-12-07T08:27:59.809477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define model architecture\ninputs = tf.keras.Input(shape=(224, 224, 3))\nx = base_model(inputs)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.3)(x)\noutputs = Dense(len(train_images.class_indices), activation='softmax')(x)\nmodel = Model(inputs, outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:28:03.946341Z","iopub.execute_input":"2024-12-07T08:28:03.946834Z","iopub.status.idle":"2024-12-07T08:28:03.990637Z","shell.execute_reply.started":"2024-12-07T08:28:03.946790Z","shell.execute_reply":"2024-12-07T08:28:03.989198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:28:08.260175Z","iopub.execute_input":"2024-12-07T08:28:08.260617Z","iopub.status.idle":"2024-12-07T08:28:08.275583Z","shell.execute_reply.started":"2024-12-07T08:28:08.260579Z","shell.execute_reply":"2024-12-07T08:28:08.274503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Callbacks\ncheckpoint = ModelCheckpoint(\"best_model.keras\", save_best_only=True, monitor=\"val_accuracy\", mode=\"max\")\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\ntensorboard = TensorBoard(log_dir=\"logs\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:28:12.309723Z","iopub.execute_input":"2024-12-07T08:28:12.310157Z","iopub.status.idle":"2024-12-07T08:28:12.316260Z","shell.execute_reply.started":"2024-12-07T08:28:12.310119Z","shell.execute_reply":"2024-12-07T08:28:12.314998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(image):\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:33:14.300577Z","iopub.execute_input":"2024-12-07T08:33:14.300985Z","iopub.status.idle":"2024-12-07T08:33:14.306584Z","shell.execute_reply.started":"2024-12-07T08:33:14.300954Z","shell.execute_reply":"2024-12-07T08:33:14.305265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the number of samples\nprint(f\"Training samples: {train_images.samples}\")\nprint(f\"Validation samples: {val_images.samples}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:33:15.064045Z","iopub.execute_input":"2024-12-07T08:33:15.064449Z","iopub.status.idle":"2024-12-07T08:33:15.070832Z","shell.execute_reply.started":"2024-12-07T08:33:15.064412Z","shell.execute_reply":"2024-12-07T08:33:15.069466Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure correct steps per epoch\nsteps_per_epoch = train_images.samples // train_images.batch_size\nvalidation_steps = val_images.samples // val_images.batch_size\n\n# Train the model\nhistory = model.fit(\n    train_images,\n    validation_data=val_images,\n    epochs=10,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    callbacks=[checkpoint, early_stopping, tensorboard],\n    verbose=1  # Display training progress\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:52:25.826851Z","iopub.execute_input":"2024-12-07T09:52:25.827368Z","iopub.status.idle":"2024-12-07T09:56:04.256687Z","shell.execute_reply.started":"2024-12-07T09:52:25.827323Z","shell.execute_reply":"2024-12-07T09:56:04.255518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:59:19.625893Z","iopub.execute_input":"2024-12-07T09:59:19.626451Z","iopub.status.idle":"2024-12-07T09:59:19.661735Z","shell.execute_reply.started":"2024-12-07T09:59:19.626377Z","shell.execute_reply":"2024-12-07T09:59:19.660695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Class indices:\", train_images.class_indices)\nprint(\"Number of classes:\", len(train_images.class_indices))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:59:57.136581Z","iopub.execute_input":"2024-12-07T09:59:57.136976Z","iopub.status.idle":"2024-12-07T09:59:57.143204Z","shell.execute_reply.started":"2024-12-07T09:59:57.136942Z","shell.execute_reply":"2024-12-07T09:59:57.142063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on test data\nresults = model.evaluate(test_images, verbose=1)\n\n# Display the results\nprint(f\"Test Loss: {results[0]:.5f}\")\nprint(f\"Test Accuracy: {results[1] * 100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T09:33:42.578316Z","iopub.execute_input":"2024-12-07T09:33:42.578764Z","iopub.status.idle":"2024-12-07T09:33:44.610900Z","shell.execute_reply.started":"2024-12-07T09:33:42.578729Z","shell.execute_reply":"2024-12-07T09:33:44.609552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Generate predictions\npredictions = model.predict(test_images)\n\n# Convert predictions to class labels\npredicted_classes = np.argmax(predictions, axis=1)\ntrue_classes = test_images.classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:17:09.131918Z","iopub.execute_input":"2024-12-07T10:17:09.132514Z","iopub.status.idle":"2024-12-07T10:17:33.123508Z","shell.execute_reply.started":"2024-12-07T10:17:09.132469Z","shell.execute_reply":"2024-12-07T10:17:33.122472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Classification report\nclass_names = list(test_images.class_indices.keys())  # Retrieve class names\nreport = classification_report(true_classes, predicted_classes, target_names=class_names)\nprint(report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:17:52.564529Z","iopub.execute_input":"2024-12-07T10:17:52.564961Z","iopub.status.idle":"2024-12-07T10:17:52.698774Z","shell.execute_reply.started":"2024-12-07T10:17:52.564923Z","shell.execute_reply":"2024-12-07T10:17:52.697168Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Confusion matrix\nconf_matrix = confusion_matrix(true_classes, predicted_classes)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Predicted Labels\")\nplt.ylabel(\"True Labels\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_history(history):\n    # Plot training & validation accuracy values\n    plt.figure(figsize=(12, 4))\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n    plt.title('Model Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    # Plot training & validation loss values\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Val Loss')\n    plt.title('Model Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Call the function to plot\nplot_history(history)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get misclassified indices\nmisclassified_indices = np.where(predicted_classes != true_classes)[0]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display a few misclassified examples\nimport random\nrandom_indices = random.sample(list(misclassified_indices), 9)\nplt.figure(figsize=(10, 10))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, idx in enumerate(random_indices):\n    plt.subplot(3, 3, i + 1)\n    img = plt.imread(test_images.filepaths[idx])\n    plt.imshow(img)\n    plt.title(f\"True: {class_names[true_classes[idx]]}, Pred: {class_names[predicted_classes[idx]]}\")\n    plt.axis(\"off\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Training samples: {train_images.samples}\")\nprint(f\"Validation samples: {val_images.samples}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T08:54:40.009531Z","iopub.status.idle":"2024-12-07T08:54:40.009912Z","shell.execute_reply.started":"2024-12-07T08:54:40.009741Z","shell.execute_reply":"2024-12-07T08:54:40.009759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# another trial","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import EfficientNetB0, ResNet50\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nimport cv2\nfrom PIL import Image, ImageChops, ImageEnhance","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:04.643018Z","iopub.execute_input":"2024-12-07T16:01:04.643631Z","iopub.status.idle":"2024-12-07T16:01:04.648853Z","shell.execute_reply.started":"2024-12-07T16:01:04.643596Z","shell.execute_reply":"2024-12-07T16:01:04.647944Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# === Helper Functions ===\ndef preprocess_image(image):\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:51:16.885507Z","iopub.execute_input":"2024-12-07T15:51:16.886400Z","iopub.status.idle":"2024-12-07T15:51:16.890522Z","shell.execute_reply.started":"2024-12-07T15:51:16.886354Z","shell.execute_reply":"2024-12-07T15:51:16.889541Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Hyperparameters and configurations\nNUM_CLASSES = 43  # Replace with your actual number of classes\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 50\nLEARNING_RATE = 1e-4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:26.628438Z","iopub.execute_input":"2024-12-07T16:01:26.629235Z","iopub.status.idle":"2024-12-07T16:01:26.633384Z","shell.execute_reply.started":"2024-12-07T16:01:26.629204Z","shell.execute_reply":"2024-12-07T16:01:26.632323Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"dataset = \"../input/yoga-posture-dataset\"  # Replace with your dataset path\nimage_dir = Path(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:27.086661Z","iopub.execute_input":"2024-12-07T16:01:27.087038Z","iopub.status.idle":"2024-12-07T16:01:27.091381Z","shell.execute_reply.started":"2024-12-07T16:01:27.087005Z","shell.execute_reply":"2024-12-07T16:01:27.090442Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"filepaths = list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.png'))\nlabels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:33.563464Z","iopub.execute_input":"2024-12-07T16:01:33.564296Z","iopub.status.idle":"2024-12-07T16:01:34.543936Z","shell.execute_reply.started":"2024-12-07T16:01:33.564256Z","shell.execute_reply":"2024-12-07T16:01:34.543247Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Create DataFrame\nfilepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\nimage_df = pd.concat([filepaths, labels], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:34.595815Z","iopub.execute_input":"2024-12-07T16:01:34.596120Z","iopub.status.idle":"2024-12-07T16:01:34.606026Z","shell.execute_reply.started":"2024-12-07T16:01:34.596091Z","shell.execute_reply":"2024-12-07T16:01:34.605110Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Split into train and test sets\ntrain_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:36.315194Z","iopub.execute_input":"2024-12-07T16:01:36.315557Z","iopub.status.idle":"2024-12-07T16:01:36.322163Z","shell.execute_reply.started":"2024-12-07T16:01:36.315521Z","shell.execute_reply":"2024-12-07T16:01:36.321137Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# Data Generators\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    validation_split=0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:37.506227Z","iopub.execute_input":"2024-12-07T16:01:37.506580Z","iopub.status.idle":"2024-12-07T16:01:37.510825Z","shell.execute_reply.started":"2024-12-07T16:01:37.506549Z","shell.execute_reply":"2024-12-07T16:01:37.510024Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"test_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:38.025091Z","iopub.execute_input":"2024-12-07T16:01:38.025790Z","iopub.status.idle":"2024-12-07T16:01:38.030062Z","shell.execute_reply.started":"2024-12-07T16:01:38.025758Z","shell.execute_reply":"2024-12-07T16:01:38.029131Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:40.189255Z","iopub.execute_input":"2024-12-07T16:01:40.190117Z","iopub.status.idle":"2024-12-07T16:01:40.449910Z","shell.execute_reply.started":"2024-12-07T16:01:40.190083Z","shell.execute_reply":"2024-12-07T16:01:40.448939Z"}},"outputs":[{"name":"stdout","text":"Found 1508 validated image filenames belonging to 43 classes.\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"val_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:01:41.675814Z","iopub.execute_input":"2024-12-07T16:01:41.676646Z","iopub.status.idle":"2024-12-07T16:01:41.700737Z","shell.execute_reply.started":"2024-12-07T16:01:41.676612Z","shell.execute_reply":"2024-12-07T16:01:41.700017Z"}},"outputs":[{"name":"stdout","text":"Found 376 validated image filenames belonging to 43 classes.\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"test_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:51:49.582511Z","iopub.execute_input":"2024-12-07T15:51:49.582861Z","iopub.status.idle":"2024-12-07T15:51:49.829148Z","shell.execute_reply.started":"2024-12-07T15:51:49.582831Z","shell.execute_reply":"2024-12-07T15:51:49.828365Z"}},"outputs":[{"name":"stdout","text":"Found 471 validated image filenames belonging to 40 classes.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Identify and handle missing classes in the test set\nnum_classes = len(train_images.class_indices)  # Total number of classes in the dataset\nmissing_classes = set(range(num_classes)) - set(test_images.class_indices.values())\nprint(f\"Missing classes in test set: {missing_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:02:37.135567Z","iopub.execute_input":"2024-12-07T16:02:37.136421Z","iopub.status.idle":"2024-12-07T16:02:37.141116Z","shell.execute_reply.started":"2024-12-07T16:02:37.136385Z","shell.execute_reply":"2024-12-07T16:02:37.140156Z"}},"outputs":[{"name":"stdout","text":"Missing classes in test set: {40, 41, 42}\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Adjust test generator labels dynamically\ndef adjust_test_labels(generator, num_classes):\n    for x_batch, y_batch in generator:\n        y_batch_one_hot = tf.one_hot(y_batch, depth=num_classes)\n        yield x_batch, y_batch_one_hot","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:03:11.228224Z","iopub.execute_input":"2024-12-07T16:03:11.228570Z","iopub.status.idle":"2024-12-07T16:03:11.233502Z","shell.execute_reply.started":"2024-12-07T16:03:11.228534Z","shell.execute_reply":"2024-12-07T16:03:11.232458Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# === Model and Optimizer Comparison ===\nmodels_to_test = {\n    \"EfficientNetB0\": EfficientNetB0,\n    \"ResNet50\": ResNet50,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:03:18.741371Z","iopub.execute_input":"2024-12-07T16:03:18.741687Z","iopub.status.idle":"2024-12-07T16:03:18.745865Z","shell.execute_reply.started":"2024-12-07T16:03:18.741661Z","shell.execute_reply":"2024-12-07T16:03:18.744814Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"optimizers_to_test = {\n    \"Adam\": Adam(learning_rate=LEARNING_RATE),\n    \"SGD\": SGD(learning_rate=LEARNING_RATE),\n    \"RMSprop\": RMSprop(learning_rate=LEARNING_RATE),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:03:18.939799Z","iopub.execute_input":"2024-12-07T16:03:18.940135Z","iopub.status.idle":"2024-12-07T16:03:18.949679Z","shell.execute_reply.started":"2024-12-07T16:03:18.940107Z","shell.execute_reply":"2024-12-07T16:03:18.948766Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Data Generators\ndef prepare_data_generators(train_df, test_df):\n    train_gen = tf.data.Dataset.from_tensor_slices((train_df['Filepath'], train_df['Label']))\n    test_gen = tf.data.Dataset.from_tensor_slices((test_df['Filepath'], test_df['Label']))\n\n    def preprocess(filepath, label):\n        img = tf.io.read_file(filepath)\n        img = tf.image.decode_image(img, channels=3)\n        img = tf.image.resize(img, IMAGE_SIZE)\n        img = tf.keras.applications.efficientnet.preprocess_input(img)\n        label = tf.one_hot(label, depth=NUM_CLASSES)\n        return img, label\n\n    train_gen = train_gen.map(preprocess).batch(BATCH_SIZE).shuffle(1024)\n    test_gen = test_gen.map(preprocess).batch(BATCH_SIZE)\n\n    return train_gen, test_gen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:03:41.865781Z","iopub.execute_input":"2024-12-07T16:03:41.866436Z","iopub.status.idle":"2024-12-07T16:03:41.872636Z","shell.execute_reply.started":"2024-12-07T16:03:41.866403Z","shell.execute_reply":"2024-12-07T16:03:41.871667Z"}},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":"results = {}","metadata":{"execution":{"iopub.status.busy":"2024-12-07T15:52:37.938056Z","iopub.execute_input":"2024-12-07T15:52:37.938689Z","iopub.status.idle":"2024-12-07T15:52:37.942474Z","shell.execute_reply.started":"2024-12-07T15:52:37.938658Z","shell.execute_reply":"2024-12-07T15:52:37.941590Z"}}},{"cell_type":"markdown","source":"# Manually encode missing classes in the test set\nfrom tensorflow.keras.utils import to_categorical\n\n# Check if any class in test set is missing\nmissing_classes = set(range(43)) - set(test_images.class_indices.values())\nprint(f\"Missing classes in test set: {missing_classes}\")\n\n# Ensure labels are encoded to fit the model's expected 43 output classes\nfor x_batch, y_batch in test_images:\n    y_batch_one_hot = to_categorical(y_batch, num_classes=43)\n    break  # Stop after checking the first batch\n\n# Continue with evaluation\ntest_loss, test_accuracy = model.evaluate(test_images, verbose=0)\n","metadata":{}},{"cell_type":"code","source":"# Model Training\ndef train_model(base_model_fn, optimizer, train_gen, val_gen, steps_per_epoch, validation_steps):\n    # Define the model\n    base_model = base_model_fn(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))\n    base_model.trainable = False  # Freeze the base model\n\n    # Build the custom model\n    inputs = tf.keras.Input(shape=(224, 224, 3))\n    x = base_model(inputs)\n    x = tf.keras.layers.Dense(256, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n    model = tf.keras.Model(inputs, outputs)\n\n    # Training loop\n    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n    train_accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n    val_accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n\n    for epoch in range(EPOCHS):\n        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n\n        # Training step\n        for step, (x_batch, y_batch) in enumerate(train_gen.take(steps_per_epoch)):\n            with tf.GradientTape() as tape:\n                logits = model(x_batch, training=True)\n                loss = loss_fn(y_batch, logits)\n            gradients = tape.gradient(loss, model.trainable_variables)\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n            train_accuracy_metric.update_state(y_batch, logits)\n\n        # Validation step\n        for x_batch, y_batch in val_gen.take(validation_steps):\n            val_logits = model(x_batch, training=False)\n            val_accuracy_metric.update_state(y_batch, val_logits)\n\n        train_acc = train_accuracy_metric.result().numpy()\n        val_acc = val_accuracy_metric.result().numpy()\n        print(f\"Train Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}\")\n\n        # Reset metrics at the end of the epoch\n        train_accuracy_metric.reset_states()\n        val_accuracy_metric.reset_states()\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:03:57.393526Z","iopub.execute_input":"2024-12-07T16:03:57.394486Z","iopub.status.idle":"2024-12-07T16:03:57.403123Z","shell.execute_reply.started":"2024-12-07T16:03:57.394450Z","shell.execute_reply":"2024-12-07T16:03:57.402344Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Evaluation Function\ndef evaluate_model(model, test_gen, test_steps):\n    accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n    for x_batch, y_batch in test_gen.take(test_steps):\n        predictions = model(x_batch, training=False)\n        accuracy_metric.update_state(y_batch, predictions)\n    return accuracy_metric.result().numpy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:04:05.458414Z","iopub.execute_input":"2024-12-07T16:04:05.459191Z","iopub.status.idle":"2024-12-07T16:04:05.465003Z","shell.execute_reply.started":"2024-12-07T16:04:05.459144Z","shell.execute_reply":"2024-12-07T16:04:05.463942Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"# === Execution ===\n# Prepare train and test generators\ntrain_gen, test_gen = prepare_data_generators(train_df, test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:04:50.386685Z","iopub.execute_input":"2024-12-07T16:04:50.387305Z","iopub.status.idle":"2024-12-07T16:04:50.637301Z","shell.execute_reply.started":"2024-12-07T16:04:50.387266Z","shell.execute_reply":"2024-12-07T16:04:50.635903Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# === Execution ===\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Prepare train and test generators\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_gen, test_gen \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[42], line 14\u001b[0m, in \u001b[0;36mprepare_data_generators\u001b[0;34m(train_df, test_df)\u001b[0m\n\u001b[1;32m     11\u001b[0m     label \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mone_hot(label, depth\u001b[38;5;241m=\u001b[39mNUM_CLASSES)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img, label\n\u001b[0;32m---> 14\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m     15\u001b[0m test_gen \u001b[38;5;241m=\u001b[39m test_gen\u001b[38;5;241m.\u001b[39mmap(preprocess)\u001b[38;5;241m.\u001b[39mbatch(BATCH_SIZE)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_gen, test_gen\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2299\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2300\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1250\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1251\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1253\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1220\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1225\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1059\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1056\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1058\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1059\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:693\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    694\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconverted_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n","File \u001b[0;32m/tmp/__autograph_generated_filenlpyj9cl.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__preprocess\u001b[0;34m(filepath, label)\u001b[0m\n\u001b[1;32m     10\u001b[0m img \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_file, (ag__\u001b[38;5;241m.\u001b[39mld(filepath),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mdecode_image, (ag__\u001b[38;5;241m.\u001b[39mld(img),), \u001b[38;5;28mdict\u001b[39m(channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m), fscope)\n\u001b[0;32m---> 12\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMAGE_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m img \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mefficientnet\u001b[38;5;241m.\u001b[39mpreprocess_input, (ag__\u001b[38;5;241m.\u001b[39mld(img),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m label \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mone_hot, (ag__\u001b[38;5;241m.\u001b[39mld(label),), \u001b[38;5;28mdict\u001b[39m(depth\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(NUM_CLASSES)), fscope)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:331\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_in_allowlist_cache(f, options):\n\u001b[1;32m    330\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: from cache\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n\u001b[0;32m--> 331\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx()\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m ag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED:\n\u001b[1;32m    334\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllowlisted: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: AutoGraph is disabled in context\u001b[39m\u001b[38;5;124m'\u001b[39m, f)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:460\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/ops/image_ops_impl.py:1461\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1459\u001b[0m images \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(images, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images\u001b[38;5;241m.\u001b[39mget_shape()\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1461\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m contains no shape.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;66;03m# TODO(shlens): Migrate this functionality to the underlying Op's.\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m is_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_23/1778104186.py\", line 9, in preprocess  *\n        img = tf.image.resize(img, IMAGE_SIZE)\n\n    ValueError: 'images' contains no shape.\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/tmp/ipykernel_23/1778104186.py\", line 9, in preprocess  *\n        img = tf.image.resize(img, IMAGE_SIZE)\n\n    ValueError: 'images' contains no shape.\n","output_type":"error"}],"execution_count":46},{"cell_type":"code","source":"print(train_df.head())\nprint(test_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:05:38.395690Z","iopub.execute_input":"2024-12-07T16:05:38.396534Z","iopub.status.idle":"2024-12-07T16:05:38.406622Z","shell.execute_reply.started":"2024-12-07T16:05:38.396478Z","shell.execute_reply":"2024-12-07T16:05:38.405674Z"}},"outputs":[{"name":"stdout","text":"                                              Filepath               Label\n983  ../input/yoga-posture-dataset/Vasisthasana/Fil...        Vasisthasana\n916  ../input/yoga-posture-dataset/Vasisthasana/Fil...        Vasisthasana\n700  ../input/yoga-posture-dataset/Urdhva Dhanurasa...  Urdhva Dhanurasana\n572  ../input/yoga-posture-dataset/Ustrasana/File2.png           Ustrasana\n553  ../input/yoga-posture-dataset/Ustrasana/File62...           Ustrasana\n                                               Filepath  \\\n1685  ../input/yoga-posture-dataset/Setu Bandha Sarv...   \n65    ../input/yoga-posture-dataset/Camatkarasana/Fi...   \n1864  ../input/yoga-posture-dataset/Adho Mukha Svana...   \n484   ../input/yoga-posture-dataset/Vrksasana/File53...   \n576   ../input/yoga-posture-dataset/Ustrasana/File35...   \n\n                         Label  \n1685  Setu Bandha Sarvangasana  \n65               Camatkarasana  \n1864      Adho Mukha Svanasana  \n484                  Vrksasana  \n576                  Ustrasana  \n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import os\n\nprint(all(os.path.exists(filepath) for filepath in train_df['Filepath']))\nprint(all(os.path.exists(filepath) for filepath in test_df['Filepath']))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:05:52.848480Z","iopub.execute_input":"2024-12-07T16:05:52.849314Z","iopub.status.idle":"2024-12-07T16:05:54.125658Z","shell.execute_reply.started":"2024-12-07T16:05:52.849279Z","shell.execute_reply":"2024-12-07T16:05:54.124743Z"}},"outputs":[{"name":"stdout","text":"True\nTrue\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"for filepath in train_df['Filepath'].iloc[:5]:\n    try:\n        img = tf.io.read_file(filepath)\n        img = tf.image.decode_image(img, channels=3)\n        print(f\"Successfully loaded: {filepath}\")\n    except Exception as e:\n        print(f\"Error loading {filepath}: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:06:04.745886Z","iopub.execute_input":"2024-12-07T16:06:04.746244Z","iopub.status.idle":"2024-12-07T16:06:04.780708Z","shell.execute_reply.started":"2024-12-07T16:06:04.746213Z","shell.execute_reply":"2024-12-07T16:06:04.779825Z"}},"outputs":[{"name":"stdout","text":"Successfully loaded: ../input/yoga-posture-dataset/Vasisthasana/File54.png\nSuccessfully loaded: ../input/yoga-posture-dataset/Vasisthasana/File24.png\nSuccessfully loaded: ../input/yoga-posture-dataset/Urdhva Dhanurasana/File42.png\nSuccessfully loaded: ../input/yoga-posture-dataset/Ustrasana/File2.png\nSuccessfully loaded: ../input/yoga-posture-dataset/Ustrasana/File62.png\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"steps_per_epoch = math.ceil(len(train_df) / BATCH_SIZE)\nvalidation_steps = math.ceil(len(test_df) / BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train and Evaluate Models\nresults = {}\nfor model_name, base_model_fn in models_to_test.items():\n    for optimizer_name, optimizer in optimizers_to_test.items():\n        print(f\"Training {model_name} with {optimizer_name} optimizer...\")\n\n        # Train the model\n        trained_model = train_model(base_model_fn, optimizer, train_gen, train_gen, steps_per_epoch, validation_steps)\n\n        # Evaluate the model\n        test_accuracy = evaluate_model(trained_model, test_gen, len(test_gen))\n        print(f\"Test Accuracy for {model_name} with {optimizer_name}: {test_accuracy:.4f}\")\n        results[(model_name, optimizer_name)] = test_accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display final results\nprint(\"\\nFinal Results:\")\nfor key, value in results.items():\n    print(f\"{key}: Accuracy = {value['accuracy']:.4f}, Loss = {value['loss']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Class indices: {train_images.class_indices}\")\nprint(f\"Number of classes: {len(train_images.class_indices)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:42:18.925686Z","iopub.execute_input":"2024-12-07T10:42:18.926060Z","iopub.status.idle":"2024-12-07T10:42:18.930938Z","shell.execute_reply.started":"2024-12-07T10:42:18.926026Z","shell.execute_reply":"2024-12-07T10:42:18.930063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Model output shape: {model.output_shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:42:26.477053Z","iopub.execute_input":"2024-12-07T10:42:26.477711Z","iopub.status.idle":"2024-12-07T10:42:26.482465Z","shell.execute_reply.started":"2024-12-07T10:42:26.477674Z","shell.execute_reply":"2024-12-07T10:42:26.481554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check batch shapes from test generator\nfor x_batch, y_batch in test_images:\n    print(f\"Input shape: {x_batch.shape}, Label shape: {y_batch.shape}\")\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:43:32.701815Z","iopub.execute_input":"2024-12-07T10:43:32.702527Z","iopub.status.idle":"2024-12-07T10:43:32.932885Z","shell.execute_reply.started":"2024-12-07T10:43:32.702490Z","shell.execute_reply":"2024-12-07T10:43:32.931860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Training set unique labels: {len(train_images.class_indices)}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:44:52.460948Z","iopub.execute_input":"2024-12-07T10:44:52.461622Z","iopub.status.idle":"2024-12-07T10:44:52.465985Z","shell.execute_reply.started":"2024-12-07T10:44:52.461584Z","shell.execute_reply":"2024-12-07T10:44:52.465003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nprint(f\"Test set unique labels: {len(test_images.class_indices)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:44:53.139523Z","iopub.execute_input":"2024-12-07T10:44:53.140309Z","iopub.status.idle":"2024-12-07T10:44:53.144450Z","shell.execute_reply.started":"2024-12-07T10:44:53.140276Z","shell.execute_reply":"2024-12-07T10:44:53.143564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Results Visualization ===\nresult_df = pd.DataFrame(results).T.reset_index()\nresult_df.columns = [\"Model\", \"Optimizer\", \"Accuracy\", \"Loss\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:24:14.687718Z","iopub.status.idle":"2024-12-07T10:24:14.688032Z","shell.execute_reply.started":"2024-12-07T10:24:14.687884Z","shell.execute_reply":"2024-12-07T10:24:14.687900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Accuracy\nplt.figure(figsize=(15, 6))\nresult_df.sort_values(\"Accuracy\", ascending=False).plot(\n    kind=\"bar\", x=\"Model\", y=\"Accuracy\", color=\"skyblue\", legend=False\n)\nplt.title(\"Model and Optimizer Accuracy Comparison\")\nplt.xlabel(\"Model + Optimizer\")\nplt.ylabel(\"Accuracy\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:24:14.689371Z","iopub.status.idle":"2024-12-07T10:24:14.689652Z","shell.execute_reply.started":"2024-12-07T10:24:14.689515Z","shell.execute_reply":"2024-12-07T10:24:14.689530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot Loss\nplt.figure(figsize=(15, 6))\nresult_df.sort_values(\"Loss\").plot(\n    kind=\"bar\", x=\"Model\", y=\"Loss\", color=\"salmon\", legend=False\n)\nplt.title(\"Model and Optimizer Loss Comparison\")\nplt.xlabel(\"Model + Optimizer\")\nplt.ylabel(\"Loss\")\nplt.xticks(rotation=45, ha=\"right\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:24:14.690760Z","iopub.status.idle":"2024-12-07T10:24:14.691074Z","shell.execute_reply.started":"2024-12-07T10:24:14.690910Z","shell.execute_reply":"2024-12-07T10:24:14.690926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display sorted results\nprint(\"Model Comparison Results:\")\nprint(result_df.sort_values(\"Accuracy\", ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T10:24:14.692479Z","iopub.status.idle":"2024-12-07T10:24:14.692757Z","shell.execute_reply.started":"2024-12-07T10:24:14.692619Z","shell.execute_reply":"2024-12-07T10:24:14.692633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# another trial another","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0, ResNet50\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:10:33.452215Z","iopub.execute_input":"2024-12-07T16:10:33.452562Z","iopub.status.idle":"2024-12-07T16:10:33.457439Z","shell.execute_reply.started":"2024-12-07T16:10:33.452536Z","shell.execute_reply":"2024-12-07T16:10:33.456466Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# === Helper Functions ===\ndef preprocess_image(image):\n    if image.mode != \"RGB\":\n        image = image.convert(\"RGB\")\n    return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:10:37.050006Z","iopub.execute_input":"2024-12-07T16:10:37.050809Z","iopub.status.idle":"2024-12-07T16:10:37.054569Z","shell.execute_reply.started":"2024-12-07T16:10:37.050777Z","shell.execute_reply":"2024-12-07T16:10:37.053586Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# === Configuration ===\nIMAGE_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 50\nLEARNING_RATE = 1e-4\nDATASET_PATH = \"../input/yoga-posture-dataset\"  # Replace with your dataset path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:10:44.268452Z","iopub.execute_input":"2024-12-07T16:10:44.268797Z","iopub.status.idle":"2024-12-07T16:10:44.273768Z","shell.execute_reply.started":"2024-12-07T16:10:44.268769Z","shell.execute_reply":"2024-12-07T16:10:44.272333Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"# === Load and Prepare Dataset ===\nimage_dir = Path(DATASET_PATH)\nfilepaths = list(image_dir.glob(r'**/*.jpg')) + \\\n            list(image_dir.glob(r'**/*.JPG')) + \\\n            list(image_dir.glob(r'**/*.png'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:10:48.385411Z","iopub.execute_input":"2024-12-07T16:10:48.385779Z","iopub.status.idle":"2024-12-07T16:10:49.569403Z","shell.execute_reply.started":"2024-12-07T16:10:48.385745Z","shell.execute_reply":"2024-12-07T16:10:49.568401Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:10:52.889886Z","iopub.execute_input":"2024-12-07T16:10:52.890319Z","iopub.status.idle":"2024-12-07T16:10:52.902558Z","shell.execute_reply.started":"2024-12-07T16:10:52.890289Z","shell.execute_reply":"2024-12-07T16:10:52.901841Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"filepaths = pd.Series(filepaths, name='Filepath').astype(str)\nlabels = pd.Series(labels, name='Label')\nimage_df = pd.concat([filepaths, labels], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:10:58.692892Z","iopub.execute_input":"2024-12-07T16:10:58.693259Z","iopub.status.idle":"2024-12-07T16:10:58.703607Z","shell.execute_reply.started":"2024-12-07T16:10:58.693228Z","shell.execute_reply":"2024-12-07T16:10:58.702752Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Split data\ntrain_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:03.036381Z","iopub.execute_input":"2024-12-07T16:11:03.036721Z","iopub.status.idle":"2024-12-07T16:11:03.043146Z","shell.execute_reply.started":"2024-12-07T16:11:03.036691Z","shell.execute_reply":"2024-12-07T16:11:03.042279Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"# Infer the number of classes\nunique_classes = sorted(train_df['Label'].unique())\nNUM_CLASSES = len(unique_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:06.481956Z","iopub.execute_input":"2024-12-07T16:11:06.482349Z","iopub.status.idle":"2024-12-07T16:11:06.490076Z","shell.execute_reply.started":"2024-12-07T16:11:06.482317Z","shell.execute_reply":"2024-12-07T16:11:06.488992Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# === Data Generators ===\ntrain_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    validation_split=0.2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:11.789322Z","iopub.execute_input":"2024-12-07T16:11:11.790148Z","iopub.status.idle":"2024-12-07T16:11:11.794245Z","shell.execute_reply.started":"2024-12-07T16:11:11.790115Z","shell.execute_reply":"2024-12-07T16:11:11.793106Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"test_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:16.132617Z","iopub.execute_input":"2024-12-07T16:11:16.133501Z","iopub.status.idle":"2024-12-07T16:11:16.137368Z","shell.execute_reply.started":"2024-12-07T16:11:16.133467Z","shell.execute_reply":"2024-12-07T16:11:16.136553Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"train_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:20.547733Z","iopub.execute_input":"2024-12-07T16:11:20.548086Z","iopub.status.idle":"2024-12-07T16:11:20.837879Z","shell.execute_reply.started":"2024-12-07T16:11:20.548056Z","shell.execute_reply":"2024-12-07T16:11:20.837200Z"}},"outputs":[{"name":"stdout","text":"Found 1508 validated image filenames belonging to 43 classes.\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"val_images = train_generator.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:28.418494Z","iopub.execute_input":"2024-12-07T16:11:28.418985Z","iopub.status.idle":"2024-12-07T16:11:28.446596Z","shell.execute_reply.started":"2024-12-07T16:11:28.418940Z","shell.execute_reply":"2024-12-07T16:11:28.445714Z"}},"outputs":[{"name":"stdout","text":"Found 376 validated image filenames belonging to 43 classes.\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"test_images = test_generator.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=IMAGE_SIZE,\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:33.321923Z","iopub.execute_input":"2024-12-07T16:11:33.322720Z","iopub.status.idle":"2024-12-07T16:11:33.407783Z","shell.execute_reply.started":"2024-12-07T16:11:33.322689Z","shell.execute_reply":"2024-12-07T16:11:33.407068Z"}},"outputs":[{"name":"stdout","text":"Found 471 validated image filenames belonging to 40 classes.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# Handle missing classes in the test set\nmissing_classes = set(range(NUM_CLASSES)) - set(test_images.class_indices.values())\nif missing_classes:\n    print(f\"Missing classes in test set: {missing_classes}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:11:55.786862Z","iopub.execute_input":"2024-12-07T16:11:55.787221Z","iopub.status.idle":"2024-12-07T16:11:55.792199Z","shell.execute_reply.started":"2024-12-07T16:11:55.787190Z","shell.execute_reply":"2024-12-07T16:11:55.791343Z"}},"outputs":[{"name":"stdout","text":"Missing classes in test set: {40, 41, 42}\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"def adjust_test_labels(generator, num_classes):\n    for x_batch, y_batch in generator:\n        adjusted_labels = tf.keras.utils.to_categorical(\n            np.array([generator.class_indices[label] for label in y_batch]),\n            num_classes=num_classes\n        )\n        yield x_batch, adjusted_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:12:01.834056Z","iopub.execute_input":"2024-12-07T16:12:01.834924Z","iopub.status.idle":"2024-12-07T16:12:01.840549Z","shell.execute_reply.started":"2024-12-07T16:12:01.834874Z","shell.execute_reply":"2024-12-07T16:12:01.839521Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Adjust test labels\nadjusted_test_gen = tf.data.Dataset.from_generator(\n    lambda: adjust_test_labels(test_images, NUM_CLASSES),\n    output_signature=(\n        tf.TensorSpec(shape=(None, *IMAGE_SIZE, 3), dtype=tf.float32),\n        tf.TensorSpec(shape=(None, NUM_CLASSES), dtype=tf.float32)\n    )\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:12:06.441731Z","iopub.execute_input":"2024-12-07T16:12:06.442623Z","iopub.status.idle":"2024-12-07T16:12:06.472418Z","shell.execute_reply.started":"2024-12-07T16:12:06.442586Z","shell.execute_reply":"2024-12-07T16:12:06.471542Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"# === Model Training ===\ndef train_model(base_model_fn, optimizer, train_gen, val_gen, num_classes):\n    # Load base model\n    base_model = base_model_fn(weights='imagenet', include_top=False, pooling='avg', input_shape=(*IMAGE_SIZE, 3))\n    base_model.trainable = False\n\n    # Add classification head\n    inputs = tf.keras.Input(shape=(*IMAGE_SIZE, 3))\n    x = base_model(inputs)\n    x = tf.keras.layers.Dense(256, activation='relu')(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n    model = tf.keras.Model(inputs, outputs)\n\n    # Compile model\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:12:12.422607Z","iopub.execute_input":"2024-12-07T16:12:12.423455Z","iopub.status.idle":"2024-12-07T16:12:12.429491Z","shell.execute_reply.started":"2024-12-07T16:12:12.423420Z","shell.execute_reply":"2024-12-07T16:12:12.428293Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# === Training Loop ===\nresults = {}\nfor model_name, base_model_fn in [(\"EfficientNetB0\", EfficientNetB0), (\"ResNet50\", ResNet50)]:\n    for optimizer_name, optimizer in [(\"Adam\", Adam(learning_rate=LEARNING_RATE)),\n                                      (\"SGD\", SGD(learning_rate=LEARNING_RATE)),\n                                      (\"RMSprop\", RMSprop(learning_rate=LEARNING_RATE))]:\n        print(f\"\\nTraining {model_name} with {optimizer_name} optimizer...\")\n        model = train_model(base_model_fn, optimizer, train_images, val_images, NUM_CLASSES)\n\n        # Train model\n        history = model.fit(\n            train_images,\n            validation_data=val_images,\n            epochs=EPOCHS,\n            steps_per_epoch=len(train_images),\n            validation_steps=len(val_images)\n        )\n\n        # Evaluate model\n        test_accuracy = model.evaluate(adjusted_test_gen, steps=len(test_images))[1]\n        print(f\"Test Accuracy for {model_name} with {optimizer_name}: {test_accuracy:.4f}\")\n        results[(model_name, optimizer_name)] = test_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T16:12:22.965426Z","iopub.execute_input":"2024-12-07T16:12:22.966054Z"}},"outputs":[{"name":"stdout","text":"\nTraining EfficientNetB0 with Adam optimizer...\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}